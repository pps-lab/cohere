


git_remote_repository:
- repo: "git@github.com:pps-lab/cohere.git"
  version: main

prj_id_prefix: "cohere"


prj_id: "{{ prj_id_prefix }}_{{ does_project_id_suffix }}"


# TODO: The following parameters define how the playbook checks whether a job finished, fetches the results and starts the next job.
# - 'job_n_tries' is the maximal number times we check the job's status before aborting
# - 'job_check_wait_time' is the time (in seconds) to wait in between checking whether a job finished
# Note that those parameters directly influence the playbook duration:
# Each experiments runs for at most #jobs * 'job_n_tries' * 'job_check_wait_time' seconds (usually less when the experiment finishes earlier).
# The experiments are mostly run concurrently (apart from the setup and cleanup parts). Thus, the experiment with the most jobs defines the
# maximal duration. But as experiments usually use fewer than 'job_n_tries' tries, an experiment with few long-running jobs can be the bottleneck too.
job_n_tries: 50 #00   # should be max 1000 (otherwise playbook freezes -> unsure why)
job_check_wait_time: 10

# if the previous job finished less than 30 seconds before
etl_minimum_delay_sec: 30


remote:
  dir: "{{ '/cluster/home/' + euler_user + '/doe-suite/' + prj_id + '/' + suite if cloud == 'euler' else '/home/ubuntu' }}"
  results_dir: "{{ '/cluster/home/' + euler_user + '/results' if cloud == 'euler' else '/home/ubuntu/results' }}"


exp_code_dir: "{{ remote.dir }}/code"

local:
  results_dir: "{{ does_project_dir }}/doe-suite-results"
  designs_dir: "{{ does_config_dir }}/designs"

exp_base:
  aws_region: eu-central-1
  name: frankfurt
  vpc_name: "{{ prj_id }}_vpc_base"
  vpc_cidr_block: 10.100.0.0/16
  vpc_subnet_name: "{{ prj_id }}_subnet_az1"
  vpc_subnet_cidr: 10.100.0.0/24
  sg_name: "{{ prj_id }}_sg"
  sg_desc: "{{ prj_id }} security group"

  eni:
  - name: "{{ prj_id }}_eni0"
    desc: "{{ prj_id }} elastic network interface 0 (for gurobi)"
  - name: "{{ prj_id }}_eni1"
    desc: "{{ prj_id }} elastic network interface 1 (for gurobi)"
  - name: "{{ prj_id }}_eni2"
    desc: "{{ prj_id }} elastic network interface 2 (for gurobi)"
  - name: "{{ prj_id }}_eni3"
    desc: "{{ prj_id }} elastic network interface 3 (for gurobi)"


gurobi:
  download: https://packages.gurobi.com/9.5/gurobi9.5.1_linux64.tar.gz
  dest: /opt
  home: /opt/gurobi951/linux64
  grbgetkey: /opt/gurobi951/linux64/bin/grbgetkey
  license_dir: /home/ubuntu
  ld_library_path: /opt/gurobi951/linux64/lib


remote_data_base_dir: "{{ '/cluster/scratch/' + euler_user + '/doe-suite/' + prj_id + '/' + suite if cloud == 'euler' else '/home/ubuntu' }}"

data_dir: "{{ remote_data_base_dir }}/data"
cargo_loc: ~/.cargo/bin/cargo

demo_project_python: "{{ exp_code_dir + '/.venv/bin/python' }}"



# if set to true, expects that in there is an accessible s3 bucket called privacy-management with a file called applications.zip in the region configured above
#     i.e., s3://privacy-management-data/applications.zip --region {{ exp_base.aws_region }}
# otherwise: it expects that an applications.zip file is already located in {{ data_dir }}
download_data_from_aws: True